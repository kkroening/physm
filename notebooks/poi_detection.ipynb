{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import Button\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "from IPython.display import Video\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from textwrap import dedent\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import ffmpeg\n",
    "import imutils\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_to_cv(image):\n",
    "    return (image.numpy().squeeze() * 255.).astype(np.uint8)\n",
    "\n",
    "\n",
    "def cv_to_tf(image):\n",
    "    return (tf.cast(image, tf.float32) / 255.)[:, :, tf.newaxis]\n",
    "\n",
    "\n",
    "def arrange_images(*rows):\n",
    "    \"\"\"Combine a table (list of list of image ndarrays) into a single image ndarray.\"\"\"\n",
    "    rows = [[tf_to_cv(col) for col in row] for row in rows]\n",
    "    blank_image = np.ones(rows[0][0].shape, dtype=np.uint8)\n",
    "    col_count = max(len(row) for row in rows)\n",
    "    rows = [list(row) + [blank_image] * (col_count - len(row)) for row in rows]\n",
    "    return cv_to_tf(np.vstack(list(np.hstack(row) for row in rows)))\n",
    "\n",
    "\n",
    "def load_video(in_filename):\n",
    "    probe = ffmpeg.probe(in_filename)\n",
    "    video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "    width = int(video_info['width'])\n",
    "    height = int(video_info['height'])\n",
    "    num_frames = int(video_info['nb_frames'])\n",
    "    out, err = (\n",
    "        ffmpeg.input(in_filename)\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "        .run(capture_stdout=True)\n",
    "    )\n",
    "    return cv_to_tf(np.frombuffer(out, np.uint8).reshape([-1, height, width, 3]))\n",
    "\n",
    "\n",
    "class AutoplayVideo(Video):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data=None,\n",
    "        url=None,\n",
    "        filename=None,\n",
    "        embed=False,\n",
    "        mimetype=None,\n",
    "        width=None,\n",
    "        height=None,\n",
    "        controls=True,\n",
    "        autoplay=True,\n",
    "        loop=True,\n",
    "    ):\n",
    "        super(AutoplayVideo, self).__init__(\n",
    "            data, url, filename, embed, mimetype, width, height\n",
    "        )\n",
    "        self.controls = controls\n",
    "        self.autoplay = autoplay\n",
    "        self.loop = loop\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        assert not self.embed, 'Embedding not implemented (yet)'\n",
    "        options = []\n",
    "        if self.width:\n",
    "            options.append('width={}'.format(self.width))\n",
    "        if self.height:\n",
    "            options.append('height={}'.format(self.height))\n",
    "        if self.autoplay:\n",
    "            options.append('autoplay')\n",
    "        if self.controls:\n",
    "            options.append('controls')\n",
    "        if self.loop:\n",
    "            options.append('loop')\n",
    "        url = self.url if self.url is not None else self.filename\n",
    "        disclaimer = 'Your browser does not support the <code>video</code> element.'\n",
    "        return '<video src=\"{}\" {}>{}</video>'.format(\n",
    "            url, ' '.join(options), disclaimer\n",
    "        )\n",
    "\n",
    "\n",
    "def erode(image, erosion, iterations=1):\n",
    "    if erosion:\n",
    "        kernel = np.ones((erosion, erosion), np.uint8)\n",
    "        image = cv_to_tf(cv2.erode(tf_to_cv(image), kernel, iterations=iterations))\n",
    "    return image\n",
    "\n",
    "\n",
    "def dilate(image, dilation, iterations=1):\n",
    "    if dilation:\n",
    "        kernel = np.ones((dilation, dilation), np.uint8)\n",
    "        image = cv_to_tf(cv2.dilate(tf_to_cv(image), kernel, iterations=iterations))\n",
    "    return image\n",
    "\n",
    "\n",
    "def blur(image, blurriness):\n",
    "    if blurriness:\n",
    "        image = cv_to_tf(cv2.blur(tf_to_cv(image), (blurriness, blurriness)))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_filename = 'vid3_small.mp4'\n",
    "frames = load_video(in_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = frames[:20]\n",
    "out_filename = 'out.mp4'\n",
    "\n",
    "do_render = lambda: None\n",
    "\n",
    "bgs = []\n",
    "back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "for frame in frames:\n",
    "    bgs.append(cv_to_tf(back_sub.apply(tf_to_cv(frame))))\n",
    "\n",
    "\n",
    "frame_count = len(frames)\n",
    "\n",
    "def match_hsv(image, lower_hsv, upper_hsv, blurriness=2, dilation=30):\n",
    "    hsv_image = tf.image.rgb_to_hsv(image)\n",
    "    hsv_image = blur(hsv_image, blurriness)\n",
    "    mask = cv_to_tf(cv2.inRange(tf_to_cv(hsv_image), lower_hsv.numpy() * 255, upper_hsv.numpy() * 255))\n",
    "    mask = dilate(mask, dilation)\n",
    "    return mask\n",
    "\n",
    "\n",
    "@interact(\n",
    "    preview_frame_num=(1, frame_count - 1),\n",
    "    end_frame_num=(1, frame_count - 1),\n",
    "    h1=(0, 255, 1),\n",
    "    s1=(0, 255, 1),\n",
    "    v1=(0, 255, 1),\n",
    "    h2=(0, 255, 1),\n",
    "    s2=(0, 255, 1),\n",
    "    v2=(0, 255, 1),\n",
    "    blurriness=(0, 20),\n",
    "    dilation1=(0, 80, 1),\n",
    "    dilation2=(0, 80, 1),\n",
    "    dilation3=(0, 80, 1),\n",
    "    min_radius=(0, 40, 1),\n",
    "    max_radius=(0, 40, 1),\n",
    ")\n",
    "def show_frame(\n",
    "    preview_frame_num=97,\n",
    "    end_frame_num=frame_count - 1,\n",
    "    h1=0,\n",
    "    s1=0,\n",
    "    v1=216,\n",
    "    h2=39,\n",
    "    s2=42,\n",
    "    v2=255,\n",
    "    blurriness=2,\n",
    "    dilation1=22,\n",
    "    dilation2=60,\n",
    "    dilation3=10,\n",
    "    min_radius=12,\n",
    "    max_radius=30,\n",
    "):\n",
    "    def render_frame(frame_num):\n",
    "        lower_hsv = tf.constant([h1 / 255, s1 / 255, v1 / 255])\n",
    "        upper_hsv = tf.constant([h2 / 255, s2 / 255, v2 / 255])\n",
    "        mask1 = match_hsv(frames[frame_num], lower_hsv, upper_hsv, blurriness, dilation1)\n",
    "        mask2 = match_hsv(frames[frame_num - 1], lower_hsv, upper_hsv, blurriness, dilation2)\n",
    "        mask3 = tf.cast(tf.cast(mask1, tf.bool) & ~tf.cast(mask2, tf.bool), tf.float32)\n",
    "        mask3 = dilate(mask3, dilation3)\n",
    "        mask1_rgb = tf.image.grayscale_to_rgb(mask1)\n",
    "        mask2_rgb = tf.image.grayscale_to_rgb(mask2)\n",
    "        mask3_rgb = tf.image.grayscale_to_rgb(mask3)\n",
    "\n",
    "        contours, _ = cv2.findContours(tf_to_cv(mask3), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        final_image = tf_to_cv(frames[frame_num])\n",
    "        for contour in contours:\n",
    "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "            if min_radius <= radius <= max_radius:\n",
    "                final_image = cv2.circle(final_image, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "        final_image = cv_to_tf(final_image)\n",
    "\n",
    "        return arrange_images(\n",
    "            (\n",
    "                #frames[frame_num],\n",
    "                final_image,\n",
    "                mask1_rgb,\n",
    "            ),\n",
    "            (\n",
    "                mask2_rgb,\n",
    "                mask3_rgb,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    out_image = render_frame(preview_frame_num)\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 9))\n",
    "    fig.tight_layout()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(tf_to_cv(out_image))\n",
    "    out_height, out_width = out_image.shape[:2]\n",
    "\n",
    "    def _render():\n",
    "        print('Rendering...')\n",
    "        process = (\n",
    "            ffmpeg.input(\n",
    "                'pipe:',\n",
    "                format='rawvideo',\n",
    "                pix_fmt='rgb24',\n",
    "                s='{}x{}'.format(out_width, out_height),\n",
    "            )\n",
    "            .filter('setpts', '1.4*PTS')\n",
    "            .output(out_filename, pix_fmt='yuv420p')\n",
    "            .overwrite_output()\n",
    "            .run_async(pipe_stdin=True)\n",
    "        )\n",
    "        with closing(process.stdin) as pipe:\n",
    "            for frame_num in tqdm(range(1, end_frame_num)):\n",
    "                out_image = render_frame(frame_num)\n",
    "                pipe.write(tf_to_cv(out_image).astype(np.uint8).tobytes())\n",
    "        process.wait()\n",
    "        print('Done.')\n",
    "        display(AutoplayVideo(out_filename, width=1400))\n",
    "\n",
    "    global do_render\n",
    "    do_render = _render\n",
    "\n",
    "\n",
    "def render(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        do_render()\n",
    "\n",
    "\n",
    "out = Output()\n",
    "render_button = Button(description='Render')\n",
    "render_button.on_click(render)\n",
    "display(render_button)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.image.rgb_to_grayscale(frames[0])\n",
    "\n",
    "#plt.imshow(x.numpy().squeeze(), cmap='gray')\n",
    "@interact(thresh=(0., 1., 0.05))\n",
    "def f(thresh=0.5):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(tf.where(x > thresh, tf.ones(x.shape), tf.zeros(x.shape)).numpy().squeeze(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
